//    gpuErrchk(cudaMalloc((void**)&gpu_PosAtomsx[0],    sizeof(double) * ncen_temp           ));
//	gpuErrchk(cudaMalloc((void**)&gpu_PosAtomsy[0],    sizeof(double) * ncen_temp           ));
//	gpuErrchk(cudaMalloc((void**)&gpu_PosAtomsz[0],    sizeof(double) * ncen_temp           ));
//	gpuErrchk(cudaMalloc((void**)&gpu_atom_z[0],       sizeof(int)    * ncen_temp           ));
//	gpuErrchk(cudaMalloc((void**)&gpu_types[0],        sizeof(int)    * nex_temp            ));
//	gpuErrchk(cudaMalloc((void**)&gpu_centers[0],      sizeof(int)    * nex_temp            ));
//	gpuErrchk(cudaMalloc((void**)&gpu_exponents[0],    sizeof(double) * nex_temp            ));
//	gpuErrchk(cudaMalloc((void**)&gpu_occ[0],          sizeof(double) * nmo_temp            ));
//	gpuErrchk(cudaMalloc((void**)&gpu_coefficients[0], sizeof(double) * nex_temp * nmo_temp ));
//	gpuErrchk(cudaMalloc((void**)&gpu_GridRho[0],      sizeof(double) * MaxGrid             ));
//	gpuErrchk(cudaMalloc((void**)&gpu_Gridx[0],        sizeof(double) * MaxGrid             ));
//	gpuErrchk(cudaMalloc((void**)&gpu_Gridy[0],        sizeof(double) * MaxGrid             ));
//	gpuErrchk(cudaMalloc((void**)&gpu_Gridz[0],        sizeof(double) * MaxGrid             ));
//	gpuErrchk(cudaMalloc((void**)&gpu_Gridaw[0],       sizeof(double) * MaxGrid             ));
//	gpuErrchk(cudaMalloc((void**)&gpu_Gridmw[0],       sizeof(double) * MaxGrid             ));
//	gpuErrchk(cudaMalloc((void**)&gpu_asym_atom_list[0], sizeof(int) * asym_atom_list.size()));
//	gpuErrchk(cudaMalloc((void**)&gpu_atom_type_list[0], sizeof(int) * atom_type_list.size()));
//	gpuErrchk(cudaMalloc((void**)&gpu_numpoints[0],    sizeof(int) * asym_atom_list.size()  ));
	for (int i = 0; i < asym_atom_list.size(); i++) {
//		gpuErrchk(cudaMalloc((void**)&gpu_atomgrid_x[0][i], sizeof(double) * num_points[i]));
//		gpuErrchk(cudaMalloc((void**)&gpu_atomgrid_y[0][i], sizeof(double) * num_points[i]));
//		gpuErrchk(cudaMalloc((void**)&gpu_atomgrid_z[0][i], sizeof(double) * num_points[i]));
//		gpuErrchk(cudaMalloc((void**)&gpu_atomgrid_w[0][i], sizeof(double) * num_points[i]));
//		gpuErrchk(cudaMalloc((void**)&(gpu_spherical_density[0][i]), sizeof(double) * num_points[i]));

//	gpuErrchk(cudaMalloc((void**)&gpu_Grids[0], sizeof(double) * MaxGrid));
	
	for (int i = 0; i < atom_type_list.size(); i++) {
//		gpuErrchk(cudaMalloc((void**)&gpu_radial_density[0][i], sizeof(double) * radial_density[i].size()));
//		gpuErrchk(cudaMalloc((void**)&gpu_radial_dist[0][i], sizeof(double) * radial_dist[i].size()));
		
	
	
	for (int i = 0; i < atom_type_list.size(); i++) 
		gpuErrchk(cudaFree(gpu_atomgrid_w[0][i]));
	gpuErrchk(cudaFree(gpu_types[0]));
	gpuErrchk(cudaFree(gpu_centers[0]));
	gpuErrchk(cudaFree(gpu_exponents[0]));
	gpuErrchk(cudaFree(gpu_coefficients[0]));
	gpuErrchk(cudaFree(gpu_occ[0]));
	
	gpuErrchk(cudaFree(gpu_Grids[0]));
	gpuErrchk(cudaFree(gpu_PosAtomsx[0]));
	gpuErrchk(cudaFree(gpu_PosAtomsy[0]));
	gpuErrchk(cudaFree(gpu_PosAtomsz[0]));
	gpuErrchk(cudaFree(gpu_atom_z[0]));
	gpuErrchk(cudaFree(gpu_GridRho[0]));
	gpuErrchk(cudaFree(gpu_Gridx[0]));
	gpuErrchk(cudaFree(gpu_Gridy[0]));
	gpuErrchk(cudaFree(gpu_Gridz[0]));
	gpuErrchk(cudaFree(gpu_Gridaw[0]));
	gpuErrchk(cudaFree(gpu_Gridmw[0]));
	gpuErrchk(cudaFree(gpu_asym_atom_list[0]));
	gpuErrchk(cudaFree(gpu_atom_type_list[0]));
	gpuErrchk(cudaFree(gpu_numpoints[0]));
	
	for(int i=0; i< atom_type_list.size(); i++){
		gpuErrchk(cudaFree(gpu_radial_density[0][i]));
		gpuErrchk(cudaFree(gpu_radial_dist[0][i]));
	}
	for (int i = 0; i < asym_atom_list.size(); i++) {
		gpuErrchk(cudaFree(gpu_spherical_density[0][i]));
		gpuErrchk(cudaFree(gpu_atomgrid_x[0][i]));
		gpuErrchk(cudaFree(gpu_atomgrid_y[0][i]));
		gpuErrchk(cudaFree(gpu_atomgrid_z[0][i]));
		gpuErrchk(cudaFree(gpu_atomgrid_w[0][i]));
	}
	
	-cif .\olex2\Wfn_job\sucrose.cif -asym_cif .\olex2\Wfn_job\sucrose.cif -wfn .\olex2\Wfn_job\sucrose.wfn -hkl .\olex2\Wfn_job\sucrose.hkl -cpus 6
	C:\Users\Florian\AppData\Roaming\Olex2Data\6bac1c4f8a3ec59d1b189b7d537b5c2c\samples\sucrose